{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98077dd3-a2c4-48b2-b0da-7ccfba14e82c",
   "metadata": {},
   "source": [
    "Question 1: Define Artificial Intelligence (AI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b960843a-3a50-43b8-bd45-f0351512c019",
   "metadata": {},
   "source": [
    "AI is the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. These machines can learn from experience, adjust to new inputs, and perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da74bda-8674-4d71-a68f-268d15033f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae0a890-cdd2-46de-a7ca-e968be4563fb",
   "metadata": {},
   "source": [
    "Question 2: Explain the differences between Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), and Data Science (DS).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e36fb-c83b-46fb-8973-ceaffc29c6ac",
   "metadata": {},
   "source": [
    "Artificial Intelligence (AI): The broad field of creating intelligent machines capable of performing tasks that require human intelligence.\n",
    "Machine Learning (ML): A subset of AI that involves training algorithms to learn from and make predictions or decisions based on data.\n",
    "Deep Learning (DL): A subset of ML that uses neural networks with many layers (deep neural networks) to analyze various factors of data.\n",
    "Data Science (DS): An interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5c9cde11-7f1b-4a2c-9699-96be78e67ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-Nearest Neighbors on test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize K-Nearest Neighbors classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Train the model on the training set\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(f\"Accuracy of K-Nearest Neighbors on test set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964259b4-b5a3-475c-b784-d7cf172700aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cf121a7-c830-48fc-929f-76df1b4b9ca8",
   "metadata": {},
   "source": [
    "Question 3: How does AI differ from traditional software development?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8852126-2845-4fdf-8207-0352a8a1f0b4",
   "metadata": {},
   "source": [
    "Traditional software development relies on explicit programming with predefined rules. AI systems learn from data, adapting to new situations without being explicitly programmed for each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2c068a36-1e27-45ee-acaa-4da44e0b06b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using Decision Tree classifier: [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Example dataset\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "\n",
    "# Initialize Decision Tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the dataset\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict using the trained classifier\n",
    "prediction = clf.predict([[2., 2.]])\n",
    "print(f\"Prediction using Decision Tree classifier: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02821b2d-f4ea-4b6d-9a12-26d5c0bdc17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05bac734-9de5-4109-b0dc-6d50e2100985",
   "metadata": {},
   "source": [
    "Question 4: Provide examples of AI, ML, DL, and DS applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5580a71-5661-4cd3-8368-d2a81977f656",
   "metadata": {},
   "source": [
    "AI: Chatbots, voice assistants (e.g., Siri, Alexa), autonomous vehicles.\n",
    "ML: Recommendation systems (e.g., Netflix, Amazon), spam email detection.\n",
    "DL: Image recognition (e.g., Google Photos), natural language processing (e.g., Google Translate).\n",
    "DS: Business intelligence (e.g., customer segmentation), predictive analytics (e.g., sales forecasting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d47a5b-639e-4d2c-9e06-d651189500e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ad72ebf-be9d-4a11-8fbb-927ec6cfb273",
   "metadata": {},
   "source": [
    "Question 5: Discuss the importance of AI, ML, DL, and DS in today's world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c88fe-c370-4322-944e-b3c6ba87bb97",
   "metadata": {},
   "source": [
    "These technologies drive innovation across various sectors by automating processes, providing insights through data analysis, enhancing customer experiences, and enabling new capabilities such as self-driving cars, personalized medicine, and advanced cybersecurity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "02fc7392-67f7-4a12-a827-9b4ec0076a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price for a house with 5 rooms: 50.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Example dataset (housing prices)\n",
    "X = [[1], [2], [3], [4]]\n",
    "y = [10, 20, 30, 40]\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict([[5]])\n",
    "print(f\"Predicted price for a house with 5 rooms: {predictions[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340537a-ae8a-415e-b647-09a0f6a997c8",
   "metadata": {},
   "source": [
    "Question 6: What is Supervised Learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ca76d-0487-4238-ab3c-0ed487e97f25",
   "metadata": {},
   "source": [
    "Supervised learning is a type of machine learning where the model is trained on labeled data. The algorithm learns the relationship between input features and the target variable, allowing it to make predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d14515db-c19b-4170-8c14-55b6316b2d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price for a house with 5 rooms: 50.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Example dataset (housing prices)\n",
    "X = [[1], [2], [3], [4]]\n",
    "y = [10, 20, 30, 40]\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict([[5]])\n",
    "print(f\"Predicted price for a house with 5 rooms: {predictions[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561990f4-8ff8-40aa-b206-7d38658ac530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9a06d4e-7733-4fcf-9d6b-e74513c45cc2",
   "metadata": {},
   "source": [
    "Question 7: Provide examples of Supervised Learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93523cc3-1d76-4b10-a4f4-99fbf315ee11",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "Logistic Regression\n",
    "Decision Trees\n",
    "Support Vector Machines (SVM)\n",
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26566a1a-247b-4b08-a140-d8dcc443ce80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b29d27a-91c7-40c5-8e0d-e9d6bf5611cf",
   "metadata": {},
   "source": [
    "Question 8: Explain the process of Supervised Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df4dfd-4f0b-44d1-b986-39f9adbbfe02",
   "metadata": {},
   "source": [
    "Collecting and labeling data\n",
    "Splitting the data into training and test sets\n",
    "Training the model on the training set\n",
    "Evaluating the model on the test set\n",
    "Fine-tuning the model to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77af5e67-0bed-4273-b597-4b730350b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.rand(100),\n",
    "    'Target': np.random.randint(2, size=100)\n",
    "})\n",
    "\n",
    "# Splitting the data\n",
    "X = data[['Feature1', 'Feature2']]\n",
    "y = data['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab674f5-2eb4-4293-ae42-af219a5a459f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d07518fa-5bc4-4c55-9d08-69906e199a04",
   "metadata": {},
   "source": [
    "Question 9: What are the characteristics of Unsupervised Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212f212-60d3-4e6b-9b43-871bbbc1eeda",
   "metadata": {},
   "source": [
    "Unsupervised learning deals with unlabeled data. The algorithm tries to learn the underlying structure of the data without explicit instructions on what to predict. It is used for clustering, association, and dimensionality reduction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d6fec-7ea4-47e6-8260-77dda2a27496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69096818-5d6c-43c4-97f5-4ab4950d3b60",
   "metadata": {},
   "source": [
    "Question 10: Give examples of Unsupervised Learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d886ea0-e530-43a4-9d5a-94d6a9a7a390",
   "metadata": {},
   "source": [
    "K-means Clustering\n",
    "Hierarchical Clustering\n",
    "Principal Component Analysis (PCA)\n",
    "Association Rule Learning (e.g., Apriori Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c803463-fab2-4974-832c-4b9490d94951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.rand(100)\n",
    "})\n",
    "\n",
    "# Training the model\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(data)\n",
    "\n",
    "# Predicting clusters\n",
    "data['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Plotting the clusters\n",
    "plt.scatter(data['Feature1'], data['Feature2'], c=data['Cluster'], cmap='viridis')\n",
    "plt.xlabel('Feature1')\n",
    "plt.ylabel('Feature2')\n",
    "plt.title('K-means Clustering')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1ca6b-6114-46e4-8abf-9722ac197208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3922795-57c0-4816-9dac-32b73e337809",
   "metadata": {},
   "source": [
    "Question 11: Describe Semi-Supervised Learning and its significance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dfe407-5155-45dd-914c-5a04cbf3341a",
   "metadata": {},
   "source": [
    "Semi-supervised learning uses a combination of a small amount of labeled data and a large amount of unlabeled data for training. It is significant because it can improve learning accuracy while reducing the cost and effort of labeling large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d7ae1afb-46be-44de-8462-60a57a0504fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.6444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:322: ConvergenceWarning: max_iter=30 was reached without convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=300, n_features=20, n_classes=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Make some labels as -1 (unlabeled)\n",
    "y_train[::2] = -1\n",
    "\n",
    "# Create and fit LabelSpreading model\n",
    "model = LabelSpreading(kernel='rbf', alpha=0.8)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Model accuracy:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5300b3b8-01b7-42ec-acee-375ada652c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37ab5a0d-668b-4524-b1a3-c0ff89480b4d",
   "metadata": {},
   "source": [
    "Question 12: Explain Reinforcement Learning and its applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1df55f-5aa8-4c1e-9172-e57e9f8c674a",
   "metadata": {},
   "source": [
    "Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by performing actions in an environment to maximize cumulative rewards. The agent receives feedback in the form of rewards or penalties and uses this to improve its future actions.\n",
    "\n",
    "Applications of RL:\n",
    "\n",
    "Robotics (e.g., robots learning to walk)\n",
    "Game playing (e.g., AlphaGo)\n",
    "Autonomous vehicles\n",
    "Recommendation systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ee169-67c8-44ea-8e05-f7cea8a70feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "619d9fcf-ce79-40e2-a2ee-0165b610d45b",
   "metadata": {},
   "source": [
    "Question 13: How does Reinforcement Learning differ from Supervised and Unsupervised Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631678af-3039-4d8f-bacb-08fcfd0abef7",
   "metadata": {},
   "source": [
    "Unlike supervised learning, which uses labeled data, and unsupervised learning, which uses unlabeled data, reinforcement learning involves learning through interaction with an environment and receiving feedback in the form of rewards or penalties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f00b07-42ba-4611-9a61-dfccb94fe1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fd4ddb0-bc60-49ed-85af-906df9c442b5",
   "metadata": {},
   "source": [
    "Question 14: What is the purpose of the Train-Test-Validation split in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c18fd67-8133-493c-ba89-9a91f351496f",
   "metadata": {},
   "source": [
    "The purpose is to evaluate the model's performance and generalize it to new, unseen data. The training set is used to train the model, the validation set to tune hyperparameters, and the test set to assess the model's final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8dc4a001-9ba2-4b47-a5f7-9776ddc664e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume X, y are the features and labels\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0fff65-1a71-434e-b62c-f16c8a1c63fe",
   "metadata": {},
   "source": [
    "Question 15: Explain the significance of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df7977-6162-4b64-b0d4-8656052c44e7",
   "metadata": {},
   "source": [
    "The training set is used to train the model and allow it to learn the patterns and relationships in the data. A well-representative training set is crucial for building a reliable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990673a7-7205-4264-80df-97d2fb03fa55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dc8995f-a8b6-4a74-a7e9-16060df671eb",
   "metadata": {},
   "source": [
    "Question 16: How do you determine the size of the training, testing, and validation sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12375ab-ae9b-4e73-928c-9851cd86cad3",
   "metadata": {},
   "source": [
    "A common approach is to split the data into 60-80% for training, 10-20% for validation, and 10-20% for testing. The exact proportions can vary based on the dataset size and the specific problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a670d1-d8e5-40bb-bed2-393752b5e5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20b6879e-83e2-4800-8a43-f3d1bf4f11ec",
   "metadata": {},
   "source": [
    "Question 17: What are the consequences of improper Train-Test-Validation splits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a117be-3135-4447-9ee1-6548af27318c",
   "metadata": {},
   "source": [
    "Improper splits can lead to biased or inaccurate models. If the test set is too small, the performance estimates may be unreliable. If the training set is too small, the model may not learn adequately, leading to underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46166dde-a9bd-46e5-898a-42627122a8e7",
   "metadata": {},
   "source": [
    "Question 18: Discuss the trade-offs in selecting appropriate split ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07540ba-1344-4359-9b5e-3ac35c78593d",
   "metadata": {},
   "source": [
    "Larger training sets can improve model learning, but smaller test and validation sets may provide unreliable performance estimates. Balancing these ratios is key to building and evaluating robust models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154539b9-9086-4c89-ae60-ca0972297d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06782a45-a714-4be0-a5b1-a15f7bdce67e",
   "metadata": {},
   "source": [
    "Question 19: Define model performance in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5401e9-32f8-4881-831d-ebea0bae64ef",
   "metadata": {},
   "source": [
    "Model performance refers to how well a machine learning model makes predictions on new, unseen data. It is typically measured using metrics such as accuracy, precision, recall, F1 score, and AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1bc803-eedc-480d-9d9a-0e700384104e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "770bc439-4d63-41c5-8c8e-71fd36dbd38e",
   "metadata": {},
   "source": [
    "Question 20: How do you measure the performance of a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a04f4d-2591-432d-9f70-c3eced959581",
   "metadata": {},
   "source": [
    "Performance is measured using evaluation metrics such as accuracy for classification, mean squared error for regression, and precision-recall for imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727911a9-2825-4309-b277-e9467a7d235b",
   "metadata": {},
   "source": [
    "Question 21: What is overfitting and why is it problematic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90afafe-ed63-4b27-a34d-a896b6d1c31d",
   "metadata": {},
   "source": [
    "Overfitting occurs when a model learns the training data too well, including noise and outliers, resulting in poor generalization to new data. It is problematic because the model performs well on training data but poorly on test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "37b96735-6025-47f8-8274-e383a4923121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume X, y are the features and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a Decision Tree model\n",
    "model = DecisionTreeClassifier(max_depth=10)  # Limiting depth to avoid overfitting\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2604f-38c9-4fe6-8b41-3c364abe470b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709eb5e8-3840-48f5-9029-ef857ff2afae",
   "metadata": {},
   "source": [
    "Question 22: Provide techniques to address overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed0e3d-bd7a-4134-8984-c1b9b544a7c5",
   "metadata": {},
   "source": [
    "Use of regularization techniques (e.g., L1, L2)\n",
    "Pruning decision trees\n",
    "Reducing model complexity\n",
    "Using dropout in neural networks\n",
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3e87aaa-909d-4a13-a2e8-dbb210143c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [-0.08954784  0.02088928 -0.06677349  0.03564708 -0.03205883]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Sample dataset\n",
    "X = np.random.rand(100, 2)\n",
    "y = np.random.randint(2, size=100)\n",
    "\n",
    "# Ridge regression with regularization\n",
    "model = Ridge(alpha=1.0)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f'Cross-validated scores: {scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675e13-2da2-454e-b15b-eac8fd9d0fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e21e490-9409-4acd-9526-dfde2cf31819",
   "metadata": {},
   "source": [
    "Question 23: Explain underfitting and its implications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0961a738-8556-4306-8e5a-f81fed60e859",
   "metadata": {},
   "source": [
    "Underfitting occurs when a model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and test data. It indicates that the model has not learned enough from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffca5fa-c594-42f1-bfd7-5fb07f823461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "742ee89b-60f2-4516-8e05-6ab8b358a4e9",
   "metadata": {},
   "source": [
    "Question 24: How can you prevent underfitting in machine learning models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066b559-1869-4204-876b-e58daf54c505",
   "metadata": {},
   "source": [
    "Use more complex models\n",
    "Increase the number of features\n",
    "Train the model longer\n",
    "Reduce regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e4dda-66cd-49b5-ba9e-982b214b8d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "352ac2f1-f8f9-43f4-85dc-8254d67d6c8a",
   "metadata": {},
   "source": [
    "Question 25: Discuss the balance between bias and variance in model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd694f2d-0b63-41af-9c90-9e97ae5497fc",
   "metadata": {},
   "source": [
    "Bias refers to errors due to overly simplistic models, leading to underfitting. Variance refers to errors due to models that are too complex, leading to overfitting. The goal is to find a balance where the model performs well on both training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d89d2-5217-434b-bd52-270c361068f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78c6f4db-4bb0-4e9e-be43-5eced5ea11b9",
   "metadata": {},
   "source": [
    "Question 26: What are the common techniques to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa14597-b197-4587-9927-df2d1345a304",
   "metadata": {},
   "source": [
    "Handling missing data is a crucial step in data preprocessing. Here are some common techniques to handle missing data:\n",
    "\n",
    "Remove Missing Data:\n",
    "\n",
    "Remove Rows: Remove rows that contain any missing values.\n",
    "Remove Columns: Remove entire columns if a significant portion of the data is missing.\n",
    "Imputation:\n",
    "\n",
    "Mean/Median/Mode Imputation: Replace missing values with the mean, median, or mode of the column.\n",
    "Forward Fill: Replace missing values with the previous value in the column.\n",
    "Backward Fill: Replace missing values with the next value in the column.\n",
    "Interpolation: Estimate missing values by interpolating between existing values.\n",
    "Using Algorithms to Predict Missing Values:\n",
    "\n",
    "K-Nearest Neighbors (KNN) Imputation: Use the K-nearest neighbors algorithm to estimate missing values.\n",
    "Multivariate Imputation by Chained Equations (MICE): Use regression models to predict and impute missing values.\n",
    "Using Machine Learning Models:\n",
    "\n",
    "Regression Imputation: Use regression models to predict missing values based on other available features.\n",
    "Deep Learning Imputation: Use neural networks to predict and impute missing values.\n",
    "Special Value Imputation:\n",
    "\n",
    "Constant Value: Replace missing values with a constant value such as -1 or 0, which indicates missingness.\n",
    "Using Indicators for Missingness:\n",
    "\n",
    "Binary Indicator: Create a new binary feature that indicates whether the value is missing (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee0cdf59-2eaf-4b1c-a5e7-73f9804c3fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing rows with missing values:\n",
      "      A    B  C\n",
      "1  2.0  2.0  2\n",
      "4  5.0  5.0  5\n",
      "After removing columns with missing values:\n",
      "    C\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n",
      "After mean imputation:\n",
      "      A         B    C\n",
      "0  1.0  3.333333  1.0\n",
      "1  2.0  2.000000  2.0\n",
      "2  3.0  3.000000  3.0\n",
      "3  4.0  3.333333  4.0\n",
      "4  5.0  5.000000  5.0\n",
      "After forward fill:\n",
      "      A    B  C\n",
      "0  1.0  NaN  1\n",
      "1  2.0  2.0  2\n",
      "2  2.0  3.0  3\n",
      "3  4.0  3.0  4\n",
      "4  5.0  5.0  5\n",
      "After backward fill:\n",
      "      A    B  C\n",
      "0  1.0  2.0  1\n",
      "1  2.0  2.0  2\n",
      "2  4.0  3.0  3\n",
      "3  4.0  5.0  4\n",
      "4  5.0  5.0  5\n",
      "After interpolation:\n",
      "      A    B  C\n",
      "0  1.0  NaN  1\n",
      "1  2.0  2.0  2\n",
      "2  3.0  3.0  3\n",
      "3  4.0  4.0  4\n",
      "4  5.0  5.0  5\n",
      "After KNN imputation:\n",
      "      A    B    C\n",
      "0  1.0  2.5  1.0\n",
      "1  2.0  2.0  2.0\n",
      "2  3.0  3.0  3.0\n",
      "3  4.0  4.0  4.0\n",
      "4  5.0  5.0  5.0\n",
      "After adding missing indicators:\n",
      "      A    B  C  A_missing  B_missing\n",
      "0  1.0  NaN  1          0          1\n",
      "1  2.0  2.0  2          0          0\n",
      "2  NaN  3.0  3          1          0\n",
      "3  4.0  NaN  4          0          1\n",
      "4  5.0  5.0  5          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/7828y2zs63dczctdd5kmqxfm0000gn/T/ipykernel_4891/2746803527.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ffill = df.fillna(method='ffill')\n",
      "/var/folders/tx/7828y2zs63dczctdd5kmqxfm0000gn/T/ipykernel_4891/2746803527.py:33: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_bfill = df.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Sample data\n",
    "data = {'A': [1, 2, np.nan, 4, 5],\n",
    "        'B': [np.nan, 2, 3, np.nan, 5],\n",
    "        'C': [1, 2, 3, 4, 5]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Remove Missing Data\n",
    "# Remove rows with missing values\n",
    "df_dropped_rows = df.dropna()\n",
    "print(\"After removing rows with missing values:\\n\", df_dropped_rows)\n",
    "\n",
    "# Remove columns with missing values\n",
    "df_dropped_cols = df.dropna(axis=1)\n",
    "print(\"After removing columns with missing values:\\n\", df_dropped_cols)\n",
    "\n",
    "# 2. Imputation\n",
    "# Mean/Median/Mode Imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_mean_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print(\"After mean imputation:\\n\", df_mean_imputed)\n",
    "\n",
    "# Forward Fill\n",
    "df_ffill = df.fillna(method='ffill')\n",
    "print(\"After forward fill:\\n\", df_ffill)\n",
    "\n",
    "# Backward Fill\n",
    "df_bfill = df.fillna(method='bfill')\n",
    "print(\"After backward fill:\\n\", df_bfill)\n",
    "\n",
    "# Interpolation\n",
    "df_interpolated = df.interpolate()\n",
    "print(\"After interpolation:\\n\", df_interpolated)\n",
    "\n",
    "# 3. Using K-Nearest Neighbors (KNN) Imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(df), columns=df.columns)\n",
    "print(\"After KNN imputation:\\n\", df_knn_imputed)\n",
    "\n",
    "# 4. Using Indicators for Missingness\n",
    "df['A_missing'] = df['A'].isna().astype(int)\n",
    "df['B_missing'] = df['B'].isna().astype(int)\n",
    "print(\"After adding missing indicators:\\n\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce204d8-4cf4-45ac-bf6d-59aabc81a35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19123ff7-3098-4039-b0c2-a9dc3aa2e2ba",
   "metadata": {},
   "source": [
    "Question 27: Explain the implications of ignoring missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8831bd4-348f-48ea-bd9f-59264360a1fa",
   "metadata": {},
   "source": [
    "Ignoring missing data can lead to several problems:\n",
    "\n",
    "Bias: Missing data can introduce bias if the data are not missing completely at random.\n",
    "Reduced Sample Size: Ignoring rows with missing data reduces the dataset size, potentially losing valuable information.\n",
    "Model Performance: The model's performance can degrade due to incomplete data, leading to inaccurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4f2d0-0057-49ec-b514-52f153693710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ea43b5-bc93-429d-b633-71e9f129ab70",
   "metadata": {},
   "source": [
    "Question 28: Discuss the pros and cons of imputation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4107a58-9e66-47ac-a8fb-8e2e4d6ada88",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "Preserve Data Size: Imputation allows you to keep all your data, avoiding the loss of information.\n",
    "Reduce Bias: Appropriate imputation methods can reduce the bias introduced by missing data.\n",
    "Improve Accuracy: Proper imputation can lead to more accurate models.\n",
    "\n",
    "\n",
    "\n",
    "Cons:\n",
    "\n",
    "Complexity: Some imputation methods can be complex and computationally intensive.\n",
    "Assumptions: Imputation methods often rely on assumptions about the data that may not hold.\n",
    "Introduced Bias: Poorly chosen imputation methods can introduce bias or noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f62f1c4-9002-4ac4-a2b5-1a76ef9ca3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  3.5\n",
      "1  2.0  2.0\n",
      "2  3.0  3.0\n",
      "3  4.0  4.0\n",
      "4  5.0  5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/7828y2zs63dczctdd5kmqxfm0000gn/T/ipykernel_4891/674088630.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['A'].fillna(df['A'].mean(), inplace=True)\n",
      "/var/folders/tx/7828y2zs63dczctdd5kmqxfm0000gn/T/ipykernel_4891/674088630.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['B'].fillna(df['B'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data with missing values\n",
    "data = {\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, 4, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Imputation with mean\n",
    "df['A'].fillna(df['A'].mean(), inplace=True)\n",
    "df['B'].fillna(df['B'].mean(), inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addea035-471b-4d98-b472-394152ae10aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2032cd-02a2-4895-ae88-632486eba9f3",
   "metadata": {},
   "source": [
    "Question 29: How does missing data affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c42e472-ff1f-4cca-882d-45cbbd55d5de",
   "metadata": {},
   "source": [
    "Missing data can affect model performance in the following ways:\n",
    "\n",
    "Reduced Accuracy: Models trained on incomplete data might not generalize well to new data.\n",
    "Bias: If the missing data are not randomly distributed, the model may become biased.\n",
    "Instability: The model's predictions can become unstable if the missing data patterns change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222a757-7cc9-4d17-8699-9d9c13b48d25",
   "metadata": {},
   "source": [
    "Question 30: Define imbalanced data in the context of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1bbc7-9a6c-4b77-bb22-21043bec24e0",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a situation where the classes in a classification problem are not represented equally. For example, in a binary classification problem, one class might constitute 90% of the data, while the other class only 10%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcaf5d6-2ab8-40c2-b332-ea463444f559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f30233-6d11-47dd-be2c-697149aab85c",
   "metadata": {},
   "source": [
    "Question 31: Discuss the challenges posed by imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa776dbc-1c1d-4c55-a64e-4f5fb86dd07b",
   "metadata": {},
   "source": [
    "Bias Towards Majority Class: Models tend to predict the majority class more often.\n",
    "Poor Predictive Performance: The minority class may have poor predictive performance, which is often the class of interest.\n",
    "Misleading Metrics: Common evaluation metrics like accuracy can be misleading in the presence of imbalanced data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02e032-c987-4e9e-b21f-a66eb99b3c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea28e972-509f-41dd-8d90-3eab45c82be8",
   "metadata": {},
   "source": [
    "Question 32: What techniques can be used to address imbalanced data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918fc6d7-a6e3-42f5-b81b-7ab8e024940c",
   "metadata": {},
   "source": [
    "Techniques include:\n",
    "\n",
    "Resampling Methods: Oversampling the minority class or undersampling the majority class.\n",
    "Synthetic Data Generation: Techniques like SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "Algorithmic Approaches: Using algorithms that are less sensitive to class imbalance, such as decision trees or ensemble methods.\n",
    "Adjusting Class Weights: Modifying the class weights in algorithms to account for the imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d69ed000-9284-4e58-a265-0515d7b32ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 990, 1: 10})\n",
      "Resampled dataset shape Counter({0: 990, 1: 990})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "\n",
    "# Create a sample imbalanced dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10,\n",
    "                           n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "\n",
    "# Apply SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc258e1a-7bb9-44cd-a9d1-df47cf71fd27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eaf6c31-ecdf-4369-b857-052fd49dc66a",
   "metadata": {},
   "source": [
    "Question 33: Explain the process of up-sampling and down-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd23cd-877f-4801-a19a-f31146910d5c",
   "metadata": {},
   "source": [
    "Up-sampling (Oversampling)\n",
    "Up-sampling, also known as oversampling, involves increasing the number of instances in the minority class to balance the class distribution. This can be done by randomly duplicating examples from the minority class or by creating synthetic examples.\n",
    "\n",
    "Pros:\n",
    "\n",
    "Helps balance the class distribution without losing any majority class instances.\n",
    "Can improve the performance of the classifier on the minority class.\n",
    "Cons:\n",
    "\n",
    "Risk of overfitting: Duplicating examples can lead to overfitting, especially if the minority class is small.\n",
    "Increased computational cost: More data points mean higher computational cost during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "001907ee-df86-469c-ad27-b464e73234c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    4\n",
      "1    4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "# Sample imbalanced dataset\n",
    "data = {\n",
    "    'feature': [1, 2, 3, 4, 5, 6],\n",
    "    'target': [0, 0, 0, 0, 1, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.target == 0]\n",
    "df_minority = df[df.target == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # Sample with replacement\n",
    "                                 n_samples=len(df_majority),    # Match number of majority class\n",
    "                                 random_state=42)  # For reproducibility\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "print(df_upsampled.target.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541cb895-dfdf-4eef-a00e-facc217a2667",
   "metadata": {},
   "source": [
    "Down-sampling (Undersampling)\n",
    "Down-sampling, or undersampling, involves reducing the number of instances in the majority class to balance the class distribution. This is typically done by randomly selecting a subset of the majority class examples.\n",
    "\n",
    "Pros:\n",
    "\n",
    "Helps balance the class distribution without adding synthetic data.\n",
    "Can reduce computational cost by reducing the number of training examples.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Loss of information: Removing majority class instances can result in loss of potentially useful information.\n",
    "Risk of underfitting: The model may not perform well due to the reduced amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a9c211e-b6bc-4c9a-af4a-5a7360d41016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    2\n",
      "1    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False,    # Sample without replacement\n",
    "                                   n_samples=len(df_minority),  # Match number of minority class\n",
    "                                   random_state=42)  # For reproducibility\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "print(df_downsampled.target.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08c162-5df1-4cd4-ad35-3daf39d097e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4bd5f21-855a-4684-b5cc-148e531bd171",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Question 34: When would you use up-sampling versus down-sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02194d-ac55-475f-bb05-dd2bc1726eb3",
   "metadata": {},
   "source": [
    "When to Use Up-sampling\n",
    "\n",
    "Small Minority Class: When the minority class is very small, down-sampling the majority class could result in too little data for training. Up-sampling can help balance the classes without losing valuable information.\n",
    "\n",
    "Preserving Data: If you want to preserve all the data points in your dataset, up-sampling is preferred because it does not remove any examples from the majority class.\n",
    "\n",
    "High Variance in Minority Class: When the minority class exhibits high variance and contains important subgroups, up-sampling can help ensure that these subgroups are well-represented in the training process.\n",
    "\n",
    "When Overfitting is Less of a Concern: Up-sampling can lead to overfitting, especially if the same examples are duplicated many times. This might be less of a concern if the model is simple or if regularization techniques are employed.\n",
    "\n",
    "When to Use Down-sampling\n",
    "\n",
    "Large Datasets: If the dataset is very large, down-sampling can reduce computational costs and training time by decreasing the number of training examples.\n",
    "\n",
    "Imbalance Not Severe: When the class imbalance is not extreme, down-sampling the majority class may provide a balanced dataset without losing too much information.\n",
    "\n",
    "Overfitting Concern: Down-sampling can be preferred when there is a high risk of overfitting due to duplicating minority class samples, as this technique reduces the dataset size instead of increasing it.\n",
    "\n",
    "Sufficient Data in Majority Class: If the majority class contains a lot of redundant or less informative data, down-sampling can remove these examples without significantly affecting model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0eca5-a755-40af-bf6c-ffe9d087b136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "193af0b4-ce6b-467d-8179-02cb82ba6d5d",
   "metadata": {},
   "source": [
    "Question 35: What is SMOTE and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d1210-6fdf-4069-b4c2-8897a6aa2c13",
   "metadata": {},
   "source": [
    "SMOTE is an advanced technique used to handle imbalanced datasets by generating synthetic examples for the minority class. It works by interpolating new examples along the line segments between existing minority class examples. This helps to create a more balanced dataset without simply duplicating the minority class samples.\n",
    "\n",
    "How SMOTE Works\n",
    "\n",
    "Identify Minority Class Samples: SMOTE first identifies the minority class samples.\n",
    "Find Nearest Neighbors: For each minority class sample, SMOTE finds its k-nearest minority class neighbors.\n",
    "Generate Synthetic Samples: New synthetic samples are generated by choosing random points along the line segments between the minority class sample and its neighbors. This is done by:\n",
    "Selecting a random neighbor.\n",
    "Choosing a random point between the minority class sample and its selected neighbor.\n",
    "Creating a synthetic sample at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e51fa9-5080-4817-9744-d61dc06c5832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "295f2df0-e5d1-471d-b788-f0e22689fa59",
   "metadata": {},
   "source": [
    "Question 36: Explain the role of SMOTE in handling imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b3767-6815-4e25-9e52-29fbc17e2b29",
   "metadata": {},
   "source": [
    "SMOTE helps balance the dataset by creating synthetic samples of the minority class. This can improve the performance of machine learning models by:\n",
    "\n",
    "Providing the model with more examples of the minority class.\n",
    "Reducing the likelihood of the model becoming biased towards the majority class.\n",
    "Improving the generalization ability of the model on minority class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b9486-3521-4a53-9e6b-ea78310a232f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97125a48-b5c8-4256-a8ff-0d6dc1816f72",
   "metadata": {},
   "source": [
    "Question 37: Discuss the advantages and limitations of SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec9bd1-e97f-4fca-a4c7-3b5be2d1804e",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "\n",
    "Balances Data: Helps in balancing the class distribution without simply duplicating minority class instances.\n",
    "Improves Model Performance: Enhances the ability of models to learn from minority class examples, potentially improving predictive performance.\n",
    "Reduces Overfitting: By generating diverse synthetic samples, it reduces the risk of overfitting compared to simple oversampling.\n",
    "\n",
    "\n",
    "\n",
    "Limitations:\n",
    "\n",
    "Computational Cost: Generating synthetic samples can be computationally intensive, especially for large datasets.\n",
    "Noise Introduction: Synthetic samples may introduce noise if not carefully controlled, potentially degrading model performance.\n",
    "Parameter Sensitivity: The effectiveness of SMOTE depends on parameters like the number of neighbors (k), which need careful tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430e202-7008-4028-8819-3502ded93f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86adcbf7-5854-4797-9a5f-dc515ed74667",
   "metadata": {},
   "source": [
    "Question 38: Provide examples of scenarios where SMOTE is beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29be01-7e0d-485b-a982-2a85d44a86ab",
   "metadata": {},
   "source": [
    "Fraud Detection: Fraudulent transactions are often much fewer than legitimate ones. SMOTE can help generate synthetic fraudulent transactions to balance the dataset.\n",
    "Medical Diagnosis: Diseases are often rare, leading to imbalanced datasets. SMOTE can generate synthetic examples of rare diseases to improve diagnostic models.\n",
    "Customer Churn Prediction: When the number of customers who churn is much smaller than those who stay, SMOTE can help balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490801e-44db-4013-9e68-8d1ca24574de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "416ec7fd-5315-43da-8dc3-952e6e1c946d",
   "metadata": {},
   "source": [
    "Question 39: Define data interpolation and its purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceac321-f365-475a-8c1c-56ea21c6aca9",
   "metadata": {},
   "source": [
    "Data Interpolation is a method of estimating unknown values that fall within the range of known data points. It is used to fill in missing data or generate smoother data representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14874305-5b79-4b44-9124-be79e7494022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "698d0576-9769-4be6-b6d3-d3ec339d8767",
   "metadata": {},
   "source": [
    "Question 40: What are the common methods of data interpolation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0200594-8bbb-4e28-a7ff-c68715512f86",
   "metadata": {},
   "source": [
    "Common Methods of Data Interpolation\n",
    "Linear Interpolation: Estimates unknown values by connecting two adjacent known values with a straight line.\n",
    "Polynomial Interpolation: Uses polynomial functions to estimate unknown values.\n",
    "Spline Interpolation: Uses piecewise polynomials to create a smooth curve through the data points.\n",
    "Nearest Neighbor Interpolation: Assigns the value of the nearest known point to the unknown point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb8330-5a62-4eb4-8449-8d3ce04707c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ca2b2fc-a192-449d-a309-fe3b8be1bf91",
   "metadata": {},
   "source": [
    "Question 41: Discuss the implications of using data interpolation in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472e28-95cc-444f-b834-249deb43724a",
   "metadata": {},
   "source": [
    "Implications of Using Data Interpolation in Machine Learning\n",
    "Improved Data Completeness: Helps in filling missing values, making the dataset more complete and usable for machine learning models.\n",
    "Smoothed Data: Can help in creating smoother data representations, which can be beneficial for models sensitive to noise.\n",
    "Potential Bias: Interpolated values are estimates and can introduce bias if the underlying assumptions do not hold true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696f3b6-efdc-4ed7-875e-1d1c5aabfa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a18acc9a-f7c7-4f2b-a2a2-c7c9b5c71983",
   "metadata": {},
   "source": [
    "Question 42: What are outliers in a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df0ad5-26a6-427d-8ede-269a2bed85b4",
   "metadata": {},
   "source": [
    "Outliers are data points that deviate significantly from the rest of the dataset. They can be caused by measurement errors, data entry errors, or genuine variability in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca55a9-6d7b-454a-927d-e02810342528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdb69d63-32cc-467d-b8e4-e973ee18913b",
   "metadata": {},
   "source": [
    "Question 43: Explain the impact of outliers on machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90074898-d6b4-42a7-9aac-3b803fd4c5ca",
   "metadata": {},
   "source": [
    "Impact of Outliers on Machine Learning Models\n",
    "Skewed Results: Outliers can skew statistical measures such as mean and standard deviation, affecting the models performance.\n",
    "Model Performance: Can degrade the performance of machine learning models by introducing noise and leading to incorrect predictions.\n",
    "Sensitivity: Models like linear regression are highly sensitive to outliers, which can lead to incorrect parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189a416-b56e-4842-b5d4-152a84488da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02075faa-2279-410c-96b9-41fbc1e88152",
   "metadata": {},
   "source": [
    "Question 44: Discuss techniques for identifying outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ea3db-bd8d-4b1f-b25c-f59a51db6923",
   "metadata": {},
   "source": [
    "Statistical Methods: Using measures like z-scores to identify points that are several standard deviations away from the mean.\n",
    "Visualization: Box plots, scatter plots, and histograms can help visually identify outliers.\n",
    "Isolation Forests: An algorithm specifically designed to detect anomalies by isolating outliers.\n",
    "Clustering Methods: Algorithms like DBSCAN can identify outliers as points that do not belong to any cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2683900c-f2c9-48bd-8df9-1e0a8ee577f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers using z-scores:\n",
      " Empty DataFrame\n",
      "Columns: [feature1, feature2]\n",
      "Index: []\n",
      "Outliers using Isolation Forest:\n",
      "    feature1  feature2  outliers\n",
      "6       300        14        -1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'feature1': [10, 12, 11, 9, 12, 11, 300, 10, 9, 10],\n",
    "        'feature2': [15, 16, 15, 14, 18, 17, 14, 13, 16, 300]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Visualize data\n",
    "sns.boxplot(data=df)\n",
    "plt.show()\n",
    "\n",
    "# Identify outliers using z-scores\n",
    "z_scores = np.abs((df - df.mean()) / df.std())\n",
    "outliers = (z_scores > 3).any(axis=1)\n",
    "print(\"Outliers using z-scores:\\n\", df[outliers])\n",
    "\n",
    "# Identify outliers using Isolation Forest\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "iso = IsolationForest(contamination=0.1)\n",
    "df['outliers'] = iso.fit_predict(data_scaled)\n",
    "print(\"Outliers using Isolation Forest:\\n\", df[df['outliers'] == -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db209d36-80ac-4e5f-9c65-462a97c9dc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01fce350-24b7-4027-af29-2000ec237177",
   "metadata": {},
   "source": [
    "Question 45: How can outliers be handled in a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3e462-4a8c-44b3-ba96-1bc95f1398bd",
   "metadata": {},
   "source": [
    "Outliers can be handled in several ways:\n",
    "\n",
    "Remove Outliers: Simply removing outliers if they are deemed to be erroneous or not relevant to the analysis.\n",
    "Transform Data: Apply transformations like log or square root to reduce the impact of outliers.\n",
    "Cap and Floor: Set upper and lower bounds to limit the effect of extreme values.\n",
    "Imputation: Replace outliers with a statistical measure like mean or median.\n",
    "Robust Models: Use models that are less sensitive to outliers, like tree-based algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7ef85-8b25-413d-bbe6-0e1c2166b72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58c52ad3-adb9-4883-9f8c-555a8a5208cf",
   "metadata": {},
   "source": [
    "Question 46: Compare and contrast Filter, Wrapper, and Embedded methods for feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285bb999-55bc-4732-9008-2d22d7ee31f3",
   "metadata": {},
   "source": [
    "Filter Methods:\n",
    "\n",
    "Description: Select features based on statistical measures without involving any machine learning algorithm.\n",
    "Example Algorithms: Chi-squared test, ANOVA, correlation coefficient.\n",
    "Advantages: Computationally efficient and quick to execute.\n",
    "Disadvantages: Ignores the interaction with the classifier, leading to potentially suboptimal feature subsets.\n",
    "\n",
    "\n",
    "Wrapper Methods:\n",
    "\n",
    "Description: Use a predictive model to evaluate the combination of features and select the best subset.\n",
    "Example Algorithms: Recursive Feature Elimination (RFE), Forward Selection, Backward Elimination.\n",
    "Advantages: Takes interaction with the classifier into account, often leading to better performance.\n",
    "Disadvantages: Computationally expensive and time-consuming, especially for large datasets.\n",
    "\n",
    "    \n",
    "Embedded Methods:\n",
    "\n",
    "Description: Feature selection is performed during the model training process.\n",
    "Example Algorithms: Lasso Regression, Ridge Regression, Decision Trees.\n",
    "Advantages: More efficient than wrapper methods, as feature selection is part of the training process.\n",
    "Disadvantages: Model-specific and may not be applicable to all types of classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65378d49-9929-46d0-ace1-dd39726186b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8678c79-fe57-4f35-bc8e-b2451636cf43",
   "metadata": {},
   "source": [
    "Question 47: Provide examples of algorithms associated with each method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce6615-bcb0-471c-9a76-3186475424c6",
   "metadata": {},
   "source": [
    "Filter Methods: Chi-squared test, ANOVA, correlation coefficient.\n",
    "Wrapper Methods: Recursive Feature Elimination (RFE), Forward Selection, Backward Elimination.\n",
    "Embedded Methods: Lasso Regression, Ridge Regression, Decision Trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b733e6-2ae1-4ca8-b737-c02936d49d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8799a9a6-2641-4d20-808c-857d4e150f26",
   "metadata": {},
   "source": [
    "Question 48: Discuss the advantages and disadvantages of each feature selection method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c352569-7184-4b0b-9789-96fb354a5ff1",
   "metadata": {},
   "source": [
    "Filter Methods:\n",
    "\n",
    "Advantages: Simple, fast, and computationally inexpensive. Good for preliminary feature selection.\n",
    "Disadvantages: Does not consider feature dependencies or interactions with the model.\n",
    "    \n",
    "Wrapper Methods:\n",
    "\n",
    "Advantages: Considers feature interactions and dependencies, often leading to better model performance.\n",
    "Disadvantages: Computationally expensive and time-consuming, especially for large feature sets.\n",
    "    \n",
    "Embedded Methods:\n",
    "\n",
    "Advantages: Efficient and integrated into the model training process, balancing between performance and computation.\n",
    "Disadvantages: Model-specific, requiring different approaches for different types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9978e-5c6e-415e-948b-9198ed3fac40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa0d25af-d8dd-45c6-bbc5-2cff2889c962",
   "metadata": {},
   "source": [
    "Question 49: Explain the concept of feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0698f1f-2fbe-4dfb-a758-5b7076476e17",
   "metadata": {},
   "source": [
    "Feature Scaling is the process of normalizing the range of features in a dataset to ensure they are on a similar scale. This is important for algorithms that are sensitive to the scale of data, such as gradient descent-based methods and distance-based algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7a446-bc35-47cd-a24d-d96497fd349b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "180f0072-0b09-4ae1-b4ec-dfd44cb955ea",
   "metadata": {},
   "source": [
    "Question 50: Describe the process of standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4dcb9f-78af-4b2e-8f83-71eeb834b45d",
   "metadata": {},
   "source": [
    "Standardization involves rescaling the features to have a mean of zero and a standard deviation of one. This is done using the formula:\n",
    "\n",
    "\n",
    "=\n",
    "(\n",
    "\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "z= \n",
    "\n",
    "(x)\n",
    "\n",
    " \n",
    "\n",
    "where \n",
    "\n",
    "x is the original value, \n",
    "\n",
    " is the mean of the feature, and \n",
    "\n",
    " is the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa499b9-ee78-4461-a98c-0b761aedc01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e97c0449-8994-45db-9a88-f43375105d79",
   "metadata": {},
   "source": [
    "Question 51: How does mean normalization differ from standardization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc3c6ff-aa98-46bb-bf9c-5a1f7ccf94c1",
   "metadata": {},
   "source": [
    "Mean Normalization adjusts the values so that the mean of the values is zero. The formula is:\n",
    "\n",
    "\n",
    "\n",
    "=\n",
    "(\n",
    "\n",
    "\n",
    "\n",
    ")\n",
    "(\n",
    "\n",
    "max\n",
    "\n",
    "\n",
    "min\n",
    ")\n",
    "x \n",
    "\n",
    " = \n",
    "(x \n",
    "max\n",
    "\n",
    " x \n",
    "min\n",
    "\n",
    " )\n",
    "(x)\n",
    "\n",
    " \n",
    "\n",
    "where \n",
    "\n",
    "x is the original value, \n",
    "\n",
    " is the mean of the feature, \n",
    "\n",
    "max\n",
    "x \n",
    "max\n",
    "\n",
    "  is the maximum value, and \n",
    "\n",
    "min\n",
    "x \n",
    "min\n",
    "\n",
    "  is the minimum value. Unlike standardization, mean normalization scales the values based on the range of the feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb9cdf-c5ad-411e-8cfb-b455da7da959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c014f01-9067-4c8d-98b5-93fb13e64da2",
   "metadata": {},
   "source": [
    "Question 52: Discuss the advantages and disadvantages of Min-Max scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df68c7c-e505-4c6d-9d7a-e669eee2eed8",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "\n",
    "Simple and easy to implement.\n",
    "Ensures that all features have the same scale, usually between 0 and 1, which can improve the performance of some algorithms.\n",
    "\n",
    "    \n",
    "Disadvantages:\n",
    "\n",
    "Sensitive to outliers, which can significantly affect the scaling.\n",
    "Does not reduce the impact of extreme values as effectively as other methods like standardization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ddd847-aa39-464d-a87d-ab34c95f686a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63e80885-7e76-486e-af83-c86fca241961",
   "metadata": {},
   "source": [
    "Question 53: What is the purpose of unit vector scaling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5d2ba-9a22-439d-8f10-5c199b9b2e3e",
   "metadata": {},
   "source": [
    "Unit Vector Scaling scales the feature vectors such that the Euclidean norm (L2 norm) of each vector is 1. This technique is useful when the direction of the data is more important than the magnitude, ensuring that the model focuses on the direction rather than the scale of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5c8c2-dd1c-4617-98b7-0330276d1897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "542d2041-c6d5-47f1-8576-b53f0acf18bc",
   "metadata": {},
   "source": [
    "Question 54: Define Principal Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bcc707-8994-408a-9549-af07272ddd0b",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a dimensionality reduction technique that transforms the original features into a new set of uncorrelated features called principal components. These principal components are ordered by the amount of variance they explain in the data. PCA helps in reducing the dimensionality of the dataset while retaining most of the variation in the data, making it easier to visualize and analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c81f0ae-af40-437b-9c70-19a50ea1ec55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.96296464 0.03703536]\n",
      "Principal components:\n",
      " [[-1.03068029 -0.21205314]\n",
      " [ 2.19045016  0.1689423 ]\n",
      " [-1.17818776  0.47577321]\n",
      " [-0.32329464  0.16119898]\n",
      " [-2.07219947 -0.25117173]\n",
      " [-1.10117414  0.2186533 ]\n",
      " [ 0.08785251 -0.43005447]\n",
      " [ 1.40605089  0.05281009]\n",
      " [ 0.53811824  0.02021127]\n",
      " [ 1.48306451 -0.20430982]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = np.array([[2.5, 2.4],\n",
    "                 [0.5, 0.7],\n",
    "                 [2.2, 2.9],\n",
    "                 [1.9, 2.2],\n",
    "                 [3.1, 3.0],\n",
    "                 [2.3, 2.7],\n",
    "                 [2, 1.6],\n",
    "                 [1, 1.1],\n",
    "                 [1.5, 1.6],\n",
    "                 [1.1, 0.9]])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Feature1', 'Feature2'])\n",
    "\n",
    "# Standardize data\n",
    "df_standardized = (df - df.mean()) / df.std()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(df_standardized)\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Principal components:\\n\", principal_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd82dbf-4489-496d-abd4-49d1b38a8830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd4f3ae-f129-4497-8d06-dabcc556d89a",
   "metadata": {},
   "source": [
    "Question 55: Explain the steps involved in PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b05c1-e8e2-48fc-9545-bdd87a0caf47",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a statistical procedure that transforms the original features into a new set of features called principal components, which are uncorrelated and ordered by the amount of variance they capture from the data. The steps involved in PCA are as follows:\n",
    "\n",
    "Standardize the Data: Center the data by subtracting the mean of each feature and scale it by dividing by the standard deviation.\n",
    "\n",
    "\n",
    "=\n",
    "(\n",
    "\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "z= \n",
    "\n",
    "(x)\n",
    "\n",
    " \n",
    "\n",
    "Compute the Covariance Matrix: Calculate the covariance matrix to understand the relationships between different features.\n",
    "\n",
    "Cov\n",
    "(\n",
    "\n",
    ")\n",
    "=\n",
    "1\n",
    "\n",
    "\n",
    "1\n",
    "(\n",
    "\n",
    "\n",
    "\n",
    ")\n",
    "Cov(X)= \n",
    "n1\n",
    "1\n",
    "\n",
    " (X \n",
    "T\n",
    " X)\n",
    "\n",
    "Compute the Eigenvalues and Eigenvectors: Calculate the eigenvalues and eigenvectors of the covariance matrix to identify the principal components.\n",
    "\n",
    "Sort Eigenvalues and Eigenvectors: Sort the eigenvalues in descending order and arrange the corresponding eigenvectors accordingly.\n",
    "\n",
    "Select Principal Components: Choose the top k eigenvectors that correspond to the k largest eigenvalues to form a new feature space.\n",
    "\n",
    "Transform the Data: Project the original data onto the new feature space using the selected eigenvectors.\n",
    "\n",
    "\n",
    "=\n",
    "\n",
    "\n",
    "Z=XW\n",
    "\n",
    "where \n",
    "\n",
    "W is the matrix of the selected eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bdcc7-412b-45ba-a4f1-497d04d42c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67612726-c75a-4b5f-806c-ebe63b928cff",
   "metadata": {},
   "source": [
    "Question 56: Discuss the significance of eigenvalues and eigenvectors in PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c407c27c-b0bd-4584-b3a1-74bc1aca4cbe",
   "metadata": {},
   "source": [
    "Eigenvalues and eigenvectors are critical in PCA because:\n",
    "\n",
    "Eigenvalues: Indicate the amount of variance captured by each principal component. Higher eigenvalues correspond to components that capture more variance.\n",
    "Eigenvectors: Represent the direction of the principal components in the feature space. These vectors define the new axes onto which the original data is projected.\n",
    "The principal components are the eigenvectors of the covariance matrix, and their corresponding eigenvalues indicate the significance of each component.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bff089-c226-4493-a008-92dc3e3e07d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c089c899-9924-457a-9e21-c3c142a20b04",
   "metadata": {},
   "source": [
    "Question 57: How does PCA help in dimensionality reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6a080-aa62-4da4-9cf6-d9487c5469f5",
   "metadata": {},
   "source": [
    "PCA helps in dimensionality reduction by transforming the original data into a lower-dimensional space while retaining most of the variance. This is achieved by:\n",
    "\n",
    "Capturing Variance: Selecting the top k principal components that capture the maximum variance from the data.\n",
    "Reducing Complexity: Reducing the number of features while preserving the essential structure and relationships in the data.\n",
    "Improving Efficiency: Making the data easier to visualize and reducing computational costs for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de12a2c-a6fa-4e22-8b53-dc6076879533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c2a6776-ed7c-4a48-a71c-81717078fb16",
   "metadata": {},
   "source": [
    "Question 58: Define data encoding and its importance in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b972faa-9f10-45e1-bc3b-3c8e1a2fa4a2",
   "metadata": {},
   "source": [
    "Data Encoding refers to the process of converting categorical data into numerical form so that machine learning algorithms can process it. It is important because most machine learning algorithms require numerical input and cannot directly handle categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123b0c7-4f8d-486f-8fa4-d4e3feec8d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cbad88a-393a-48d5-a16b-06d53fe37161",
   "metadata": {},
   "source": [
    "Question 59: Explain Nominal Encoding and provide an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e07a40-32fc-4e8e-9072-8ed3c10e3ce5",
   "metadata": {},
   "source": [
    "Nominal Encoding converts categorical data into numerical form without implying any order or ranking among the categories.\n",
    "\n",
    "Example:\n",
    "Using LabelEncoder from sklearn to encode nominal data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68f12ca8-ab62-44c8-b6d0-ccb698c74248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = ['red', 'green', 'blue']\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_data = label_encoder.fit_transform(data)\n",
    "print(encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0d5f9-0466-4d28-bb78-d9e27287c495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "899e71f8-6495-4825-9f03-4b1972562ba3",
   "metadata": {},
   "source": [
    "Question 60: Discuss the process of One Hot Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d4cde-dde5-4cf5-ae9d-a696d8087b3b",
   "metadata": {},
   "source": [
    "One Hot Encoding converts categorical data into a binary vector representation, where each category is represented by a vector with a single high (1) value and the rest low (0).\n",
    "\n",
    "Example:\n",
    "Using OneHotEncoder from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2b107-b2d8-490b-9eff-14dcbf96dec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e557b21c-16ef-4756-b564-d54d123b3ea4",
   "metadata": {},
   "source": [
    "Question 61: How do you handle multiple categories in One Hot Encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465083a-1802-4bd3-bdf1-9c2ae5dbec4d",
   "metadata": {},
   "source": [
    "One Hot Encoding handles multiple categories by creating a binary vector for each category. For instance, if there are three categories ('red', 'green', 'blue'), One Hot Encoding creates three binary vectors, each with a single high (1) value and the rest low (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c95e74-e891-49fc-bdb6-514ba81427b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96f8f2e4-b3c3-4435-bac6-6ae1e1c6a603",
   "metadata": {},
   "source": [
    "Question 62: Explain Mean Encoding and its advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175d900c-578d-4683-9712-3d73bf38528a",
   "metadata": {},
   "source": [
    "Mean Encoding (also known as target encoding) replaces each category with the mean of the target variable for that category.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Captures Target Relationship: Takes into account the relationship between the category and the target variable.\n",
    "Reduces Dimensionality: Unlike One Hot Encoding, it doesn't increase the dimensionality of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "af3d8951-a86b-4b81-9397-5dea461d4f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color  target  color_mean_encoded\n",
      "0    red       1                 1.0\n",
      "1  green       0                 0.0\n",
      "2   blue       1                 0.5\n",
      "3    red       1                 1.0\n",
      "4   blue       0                 0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'color': ['red', 'green', 'blue', 'red', 'blue'],\n",
    "                     'target': [1, 0, 1, 1, 0]})\n",
    "\n",
    "mean_encoded = data.groupby('color')['target'].mean()\n",
    "data['color_mean_encoded'] = data['color'].map(mean_encoded)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2293ebda-be17-4a74-905b-47a299fc9e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "188706a1-bf7e-4ccd-b086-74953f278815",
   "metadata": {},
   "source": [
    "Question 63: Provide examples of Ordinal Encoding and Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4d4f8f4b-4f5b-4a5f-be29-e2515b85e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a4c9f046-a1c2-4ca8-8aaa-3acb604ecfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     size  size_encoded\n",
      "0   small             1\n",
      "1  medium             2\n",
      "2   large             3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'size': ['small', 'medium', 'large']})\n",
    "data['size_encoded'] = data['size'].map({'small': 1, 'medium': 2, 'large': 3})\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1a81174b-546b-4f5a-8536-9d75587a4313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "61715290-6221-4415-ab4e-7b9ff3de44e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = ['red', 'green', 'blue']\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_data = label_encoder.fit_transform(data)\n",
    "print(encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60011f40-ddbb-4e3d-9962-78f26d07aa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ac07a7d-79e2-4764-a59c-1e0eda871b3f",
   "metadata": {},
   "source": [
    "Question 64: What is Target Guided Ordinal Encoding and how is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161f8b1-f710-42ee-afb8-95f67674c0a5",
   "metadata": {},
   "source": [
    "Target Guided Ordinal Encoding assigns numerical values to categories based on the mean of the target variable for each category, thus preserving the ordinal relationship between categories and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3b404248-0f61-4a6b-a291-a4f9d963d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color  target  color_ordinal_encoded\n",
      "0    red       1                      3\n",
      "1  green       0                      1\n",
      "2   blue       1                      2\n",
      "3    red       1                      3\n",
      "4   blue       0                      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'color': ['red', 'green', 'blue', 'red', 'blue'],\n",
    "                     'target': [1, 0, 1, 1, 0]})\n",
    "\n",
    "mean_encoded = data.groupby('color')['target'].mean().sort_values()\n",
    "ordinal_encoding = {k: i for i, k in enumerate(mean_encoded.index, 1)}\n",
    "data['color_ordinal_encoded'] = data['color'].map(ordinal_encoding)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544015fc-c9db-4d1a-b5be-0ccb08afe9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "918a2ece-02ac-440f-a2f9-f24031d654b7",
   "metadata": {},
   "source": [
    "Question 65: Define covariance and its significance in statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb6b6b-ac56-462a-bbf0-33d4122af533",
   "metadata": {},
   "source": [
    "Covariance measures the degree to which two random variables change together. It indicates the direction of the linear relationship between variables. A positive covariance indicates that higher values of one variable tend to be associated with higher values of the other, while a negative covariance indicates an inverse relationship.\n",
    "\n",
    "Significance:\n",
    "\n",
    "Helps understand how variables are related to each other.\n",
    "Used in portfolio management to understand the relationship between different assets.\n",
    "Used in statistics for dimensionality reduction techniques like Principal Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e7b6e274-6504-4f9b-8ad7-2cb88b7b492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance between x and y: -2.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "# Calculate covariance\n",
    "covariance = np.cov(x, y)[0, 1]\n",
    "\n",
    "print(f\"Covariance between x and y: {covariance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca46399-47a8-4766-83da-17395584f9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6c6bf3a-47e8-4f66-a112-56d82bb7d47a",
   "metadata": {},
   "source": [
    "Question 66: Explain the process of correlation check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b41ca29-2a01-42e6-ba59-81ff9b2de65e",
   "metadata": {},
   "source": [
    "Correlation check involves assessing the strength and direction of association between two variables:\n",
    "\n",
    "Calculate Correlation Coefficient: Typically using methods like Pearson's correlation coefficient.\n",
    "Interpret Coefficient: Ranges from -1 to +1; closer to -1 or +1 indicates strong correlation.\n",
    "Visualize: Scatter plots can provide a visual representation of the relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2e2d354e-e3e8-4e78-9a1e-6d7b530057bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient Matrix:\n",
      "     A    B\n",
      "A  1.0 -1.0\n",
      "B -1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [5, 4, 3, 2, 1]\n",
    "})\n",
    "\n",
    "correlation_matrix = data.corr(method='pearson')\n",
    "\n",
    "print(\"Pearson Correlation Coefficient Matrix:\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a26fb-1828-453f-95a3-1c30c189a220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31e2165a-1989-4e0a-a363-84c9beb84fbd",
   "metadata": {},
   "source": [
    "Question 67: What is the Pearson Correlation Coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959a9fb-b131-499a-96eb-1949231f7b57",
   "metadata": {},
   "source": [
    "Pearson Correlation Coefficient measures the linear relationship between two continuous variables. It is calculated as the covariance of the variables divided by the product of their standard deviations. It ranges from -1 (perfect negative correlation) to +1 (perfect positive correlation), with 0 indicating no linear correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a4cdd876-4814-4eaa-afa4-1ca7f5b968b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient between x and y: -0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "pearson_coefficient = np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "print(f\"Pearson Correlation Coefficient between x and y: {pearson_coefficient}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4900f91-ab0b-4c61-8679-45d05c4f0aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8281b06f-e282-40bb-acf6-8b7e676c6721",
   "metadata": {},
   "source": [
    "Question 68: How does Spearman's Rank Correlation differ from Pearson's Correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5809dd78-2af1-4f9b-8f70-90cb7a438dea",
   "metadata": {},
   "source": [
    "Spearmans Rank Correlation assesses how well the relationship between two variables can be described using a monotonic function. It does not assume that the relationship is linear, making it suitable for ordinal or non-linear data. Pearson's correlation, on the other hand, measures linear relationships specifically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6529e9b2-cb8d-4df5-90eb-f89f56f647a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman's Rank Correlation Matrix:\n",
      "     A    B\n",
      "A  1.0 -1.0\n",
      "B -1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "spearman_corr = data.corr(method='spearman')\n",
    "\n",
    "print(\"Spearman's Rank Correlation Matrix:\")\n",
    "print(spearman_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31bf2c-df48-4a76-bbb7-d24a10351ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78e25875-6313-4a9a-b090-6595c410ce4d",
   "metadata": {},
   "source": [
    "Question 69: Discuss the importance of Variance Inflation Factor (VIF) in feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0c90f-3a9d-4ea3-a25f-8fd65757244b",
   "metadata": {},
   "source": [
    "Variance Inflation Factor (VIF) measures how much the variance of an estimated regression coefficient is inflated due to collinearity with other predictors. High VIF values indicate that a predictor variable is highly correlated with other predictors, which can lead to unreliable regression coefficients.\n",
    "\n",
    "Importance:\n",
    "\n",
    "Helps identify multicollinearity in regression models.\n",
    "Guides in selecting independent variables that are less correlated with each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d3e792dc-ca11-4918-871b-148219f8f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Inflation Factor (VIF) Results:\n",
      "  Feature       VIF\n",
      "0       A  1.680556\n",
      "1       B  1.680556\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "X = data[['A', 'B']]\n",
    "\n",
    "# Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "\n",
    "print(\"Variance Inflation Factor (VIF) Results:\")\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb53eab-39b8-4062-86ea-bad5409c7cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72854722-5bc3-4e88-bd2b-71295f202252",
   "metadata": {},
   "source": [
    "Question 70: Define feature selection and its purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d1e7b-aff5-4172-ae35-0bbd55e47f18",
   "metadata": {},
   "source": [
    "Feature Selection is the process of choosing a subset of relevant features (variables, predictors) for use in model construction.\n",
    "\n",
    "Purpose:\n",
    "\n",
    "Reduces overfitting by removing irrelevant features.\n",
    "Improves model interpretability and performance.\n",
    "Reduces computational complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "58da2554-8450-473c-a518-927c3b87dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "k_best_features = SelectKBest(score_func=chi2, k=2)\n",
    "X_selected = k_best_features.fit_transform(X, y)\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(X_selected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888f01be-7c04-44f9-8a97-9d22d7b23dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad12acbb-4778-40cb-808b-9d9bffa01004",
   "metadata": {},
   "source": [
    "Question 71: Explain the process of Recursive Feature Elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16b01a-403b-4d61-9a2f-2c4e98f25556",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination (RFE):\n",
    "\n",
    "Process: Iteratively removes features and builds a model, evaluating the model performance after each removal.\n",
    "Selection Criterion: Typically based on model performance metrics (e.g., accuracy, R-squared).\n",
    "Stop Criterion: Stops when the desired number of features is reached or when performance no longer improves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c3d34a4a-f603-488f-a47f-af379cc39b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features with RFE:\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "estimator = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(estimator, n_features_to_select=2)\n",
    "X_rfe = rfe.fit_transform(X, y)\n",
    "\n",
    "print(\"Selected Features with RFE:\")\n",
    "print(X_rfe.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f7f2c-b057-4890-a22d-a3f4450e7a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ead3a0e-aae6-46d0-9793-0bcaf1716648",
   "metadata": {},
   "source": [
    "Question 72: How does Backward Elimination work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232f049-e76a-4f1b-b075-ac35c68451b7",
   "metadata": {},
   "source": [
    "Backward Elimination:\n",
    "\n",
    "Process: Starts with all features and iteratively removes the least significant feature based on a predefined criterion (e.g., p-value in regression).\n",
    "Advantages: Efficient for datasets with a large number of features.\n",
    "Disadvantages: Assumes the model is correctly specified from the beginning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6cf4d796-f26e-41d9-a054-46457dd9b18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after Backward Elimination:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.972\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.971\n",
      "Method:                 Least Squares   F-statistic:                              1699.\n",
      "Date:                Wed, 17 Jul 2024   Prob (F-statistic):                   7.71e-114\n",
      "Time:                        16:49:28   Log-Likelihood:                          16.921\n",
      "No. Observations:                 150   AIC:                                     -27.84\n",
      "Df Residuals:                     147   BIC:                                     -18.81\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "1             -0.1042      0.012     -8.629      0.000      -0.128      -0.080\n",
      "3              0.2406      0.042      5.743      0.000       0.158       0.323\n",
      "4              0.5866      0.088      6.659      0.000       0.413       0.761\n",
      "==============================================================================\n",
      "Omnibus:                        0.462   Durbin-Watson:                   1.162\n",
      "Prob(Omnibus):                  0.794   Jarque-Bera (JB):                0.184\n",
      "Skew:                          -0.041   Prob(JB):                        0.912\n",
      "Kurtosis:                       3.150   Cond. No.                         39.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "X_df = pd.DataFrame(X)\n",
    "\n",
    "model = sm.OLS(y, X_df).fit()\n",
    "\n",
    "while model.pvalues.max() > 0.05:\n",
    "    # Identify the feature with the highest p-value\n",
    "    max_pvalue_feature = model.pvalues.idxmax()\n",
    "    \n",
    "    \n",
    "    X_df = X_df.drop(columns=[max_pvalue_feature])\n",
    "    \n",
    "    \n",
    "    model = sm.OLS(y, X_df).fit()\n",
    "\n",
    "print(\"Features after Backward Elimination:\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46937364-4a06-473e-93da-8d4b8e60a6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c998e97b-a591-4611-84fd-0508b83a4b06",
   "metadata": {},
   "source": [
    "Question 73: Discuss the advantages and limitations of Forward Elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50ae37e-9227-414a-a86d-e55f30cf748f",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "\n",
    "Sequentially builds the model, starting from the most significant feature.\n",
    "Can be effective for datasets where each added feature improves model performance.\n",
    "\n",
    "Limitations:\n",
    "\n",
    "Computationally expensive, especially for large datasets.\n",
    "May overfit the model if not cross-validated properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8ff84168-9e3c-401f-8cfb-a6dceef9b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features with Forward Selection:\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "selector = SequentialFeatureSelector(estimator, direction='forward', n_features_to_select=2)\n",
    "X_forward = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Selected Features with Forward Selection:\")\n",
    "print(X_forward.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d6554-f864-42b4-a952-8879ae0dc413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07611dcc-e79d-4648-a58f-a9a76295c9e0",
   "metadata": {},
   "source": [
    "Question 74: What is feature engineering and why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8dfc6-9fdb-4fd6-a570-e401ecc93d17",
   "metadata": {},
   "source": [
    "Feature Engineering involves creating new features or transforming existing ones to improve model performance or understanding of the dataset.\n",
    "\n",
    "Importance:\n",
    "\n",
    "Enhances model accuracy by providing more predictive features.\n",
    "Improves model interpretability.\n",
    "Mitigates issues like overfitting and underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fdf5e24f-5f8b-4e5c-91c8-aac44d43c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "Polynomial features:\n",
      "[[ 1.  1.  2.  1.  2.  4.]\n",
      " [ 1.  3.  4.  9. 12. 16.]\n",
      " [ 1.  5.  6. 25. 30. 36.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1, 2],\n",
    "              [3, 4],\n",
    "              [5, 6]])\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(X)\n",
    "print(\"\\nPolynomial features:\")\n",
    "print(X_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231f7de-0a24-42e1-8bb7-789edc290685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e9868bd-3a92-4c51-a68f-da9d693373fc",
   "metadata": {},
   "source": [
    "Question 75: Discuss the steps involved in feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5257aed-539a-4b48-9c93-7e2f6ebb4264",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "Brainstorming: Generate ideas for new features based on domain knowledge.\n",
    "Feature Creation: Construct new features from existing data.\n",
    "Feature Transformation: Apply transformations like scaling or encoding.\n",
    "Feature Selection: Choose relevant features using techniques like correlation check or domain expertise validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e04829ad-1215-4e15-bead-883efd6b347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with date-time features:\n",
      "        date  value  year  month\n",
      "0 2023-01-01     10  2023      1\n",
      "1 2023-02-01     20  2023      2\n",
      "2 2023-03-01     30  2023      3\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'date': ['2023-01-01', '2023-02-01', '2023-03-01'],\n",
    "    'value': [10, 20, 30]\n",
    "})\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "print(\"Data with date-time features:\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25db58c-7c38-46e1-a078-8a5b6df6774a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34c8a700-6a7f-4cb0-be47-d556b6f09f5d",
   "metadata": {},
   "source": [
    "Question 76: Provide examples of feature engineering techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093b11b-a488-4e7f-9897-7b46f32a59bb",
   "metadata": {},
   "source": [
    "Examples:\n",
    "\n",
    "Polynomial Features: Creating interaction terms between features.\n",
    "Binning: Grouping continuous variables into categories.\n",
    "Date-Time Features: Extracting day of week, month, or other temporal information.\n",
    "Text Feature Extraction: Using TF-IDF or word embeddings for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b8e4735a-1b1e-463d-b6a0-8415145775c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original numerical data:\n",
      "[[1.1]\n",
      " [2.3]\n",
      " [3.6]\n",
      " [4.8]]\n",
      "\n",
      "Binned data:\n",
      "[[0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "X = np.array([[1.1], [2.3], [3.6], [4.8]])\n",
    "\n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "X_binned = est.fit_transform(X)\n",
    "\n",
    "print(\"Original numerical data:\")\n",
    "print(X)\n",
    "print(\"\\nBinned data:\")\n",
    "print(X_binned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8229b-c06f-4a06-a496-c04b3237904d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fec4fc7-9122-459c-b886-db8930b5417e",
   "metadata": {},
   "source": [
    "Question 77: How does feature selection differ from feature engineering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10af719-dfe9-4b18-86e0-8c91fad57faf",
   "metadata": {},
   "source": [
    "Feature Selection: Involves choosing the most relevant features from the dataset to build the model.\n",
    "\n",
    "Feature Engineering: Involves creating new features or transforming existing ones to improve model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "985c7311-b022-4ee9-b64f-1d62c0c5623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using SelectKBest:\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Selected features using SelectKBest:\")\n",
    "print(X_selected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a5059-4c12-4ec2-bbf0-9d30f587b1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f47f269-e314-44ee-89f2-5ee4baf7e80b",
   "metadata": {},
   "source": [
    "Question 78: Explain the importance of feature selection in machine learning pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a999b9-c503-46da-9260-340e820c82a3",
   "metadata": {},
   "source": [
    "Importance:\n",
    "\n",
    "Reduces overfitting by selecting only the most relevant features.\n",
    "Speeds up training and inference times.\n",
    "Improves model interpretability by focusing on the most impactful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f53c1c10-cecf-487a-b030-17658ffb4add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;feature_selection&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestClassifier())),\n",
       "                (&#x27;classification&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;feature_selection&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestClassifier())),\n",
       "                (&#x27;classification&#x27;, RandomForestClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;feature_selection: SelectFromModel<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_selection.SelectFromModel.html\">?<span>Documentation for feature_selection: SelectFromModel</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SelectFromModel(estimator=RandomForestClassifier())</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('feature_selection',\n",
       "                 SelectFromModel(estimator=RandomForestClassifier())),\n",
       "                ('classification', RandomForestClassifier())])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(RandomForestClassifier())),\n",
    "    ('classification', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85d932-afad-4262-a6b9-7d8f7cef21e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37370b18-3969-48d4-b930-664432b9ccc0",
   "metadata": {},
   "source": [
    "Question 79: Discuss the impact of feature selection on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a2d52-f519-4f27-9d9c-222ccb2a218f",
   "metadata": {},
   "source": [
    "Impact:\n",
    "\n",
    "Positive: Improves model accuracy and generalization by reducing noise from irrelevant features.\n",
    "Negative: If not done correctly, can lead to underfitting or loss of important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "75eb114b-6f9f-4cc3-919a-cffa078be381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy without feature selection: 0.9733333333333334\n",
      "Mean accuracy with feature selection: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"Mean accuracy without feature selection: {scores.mean()}\")\n",
    "\n",
    "selector = SelectFromModel(RandomForestClassifier())\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "scores_selected = cross_val_score(model, X_selected, y, cv=5)\n",
    "print(f\"Mean accuracy with feature selection: {scores_selected.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b476d3a-96a3-42bf-b792-89ce50643731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6bb7629-f4dc-48c8-8837-3e190d1d0f7e",
   "metadata": {},
   "source": [
    "Question 80: How do you determine which features to include in a machine-learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3050437-73cb-4a3b-917b-b6d86e37bbaa",
   "metadata": {},
   "source": [
    "Methods:\n",
    "\n",
    "Filter Methods: Based on statistical measures like correlation, chi-squared, or mutual information.\n",
    "Wrapper Methods: Use a predictive model to evaluate the importance of features.\n",
    "Embedded Methods: Feature selection is integrated into the model training process (e.g., Lasso regression, Random Forest feature importance).\n",
    "Choosing the right method depends on the dataset size, complexity, and specific requirements of the machine learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "04a028ce-6e81-4bad-a556-aefa98f3a9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "Feature 0: 0.09964032003930655\n",
      "Feature 1: 0.023529341663067218\n",
      "Feature 2: 0.3985512529443518\n",
      "Feature 3: 0.4782790853532745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for i, importance in enumerate(feature_importances):\n",
    "    print(f\"Feature {i}: {importance}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21490fc-8d02-41fe-bcd7-f8db17012d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
